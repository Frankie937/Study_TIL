(링크: https://www.youtube.com/watch?v=DIYT8hRLq2Y&t=1101s) 

(아직 정리하지 않음. 메모만)
---

### AI agent는 어떻게 작동하는가 ? 
* prompt engineering 
얼마나 지시를 명확하게 잘 내리느냐 (모델이 잘 알아 듣도록)
instruction following 잘 시키기 위함

* context engineering
LLM이 의사결정을 잘 하도록, 쌓여놓은 context를 얼마나 잘 정리하느냐
필요없는 정보를 버리거나, 중복제거, 압축, 요약, 가지치기등을 하는 걸 통해서 
dead, summarization, compression, pruning 등등의 작업들 


* tool calling이 등장하면서 히든피스가 되었다고 생각됨. system prompt를 던져주고 내가 어떤 도구를 호풀할 수 있고 입력프롬프트를 처리하기 위해 내가 보유한 도구 중에 어떤 걸 호출해야 하는 지 
이러한 부분들이 학습이 되어있는 것.  내부적으로 텍스트를 뱉어내고 있음 (서버단에서는) 
* 텍스트를 파싱가능한 상태로 json object로, 명세서형식으로 json 포맷이 구성되어 던져진다 
* 사용할 도구가 많다는 것은 AI모델이 헷갈릴 포인트를 줄 수 있음 
* 어떤 도구를 가지고 있는지에 대한 문맥이 있고, tool 호출 정보(함수이름 파싱) > llm이 생성한 파라미터 매핑시켜 넣으면서 tool 호출 결과를 받게되는 것 (tool 호출과 응답이 pair로 쌓이게 됨)
* context engineering - 일종의 prompt 엔지니어링이라고 생각. 기본적으로 모델이 의사결정을 내리기 위해 context길이를 얼마나 잘 관리하는 지가 굉장히 중요한 요점 



### AI 에이전트는 어떻게 평가할 것인가? 
밑바닥부터 구현 ?

* 평가 3가지 - 무엇을 평가할 것인가 
1) 에이전트 end to end 평가 
사용자가 요청을 보냈을 때 만족스런 응답을 내놓느냐 
2) 에이전트 단위평가 
만약 컨텍스트 길이가 굉장히 길어져도 잘 도구를 선별하고 호출할 수 있다면 멀티에이전트 시스템이 필요 없어질거라 생각
그러나, 지금 그게 잘 안되니 일의 분업화를 잘 하기 위해 멀티에이전트 시스템이 나왔다고 생각함 
그래서 각각의 에이전트 단위로 평가할 수 있음 
(에이전트 별로 매핑해놓은 도구들이 기대한 sequence 대로 얼마나 적절하게 잘 호출되는 지, 각각의 호출된 결과로 llm이 답변을 잘 작성했는지) 
3) 도구호출 평가 

* 검증가능한 정량적 평가(Hard evaluation)/ 검증가능하지 않지만 점수평가가 가능한 정성적 평가 (Soft evaluation) 
   - 에이전트 시스템 - ground truth를 잘 정의하는 게 중요 
   - 똑같은 의미지만 수백, 수천가지의 다른 표현으로 표현할 수 있는 자연어에 대한 표현 매핑을 얼마나 잘 정의되어있고, 학습 되어있는지에 따라 
   - 최종 답변도 자연어이기에 평가하기가 어려운데 각 에이전트 단위로 평가하는 건 더 쉬울 수 있음 (단계별로 분해해서 평가를 하는 방법이 있는 것)

* soft evaluation 
모델이 새로나온다는 것 - 새로운 데이터가 학습되어 있음 




### 밑바닥부터 AI Agent 구현 왜?
- langchain 커뮤니티 - 수백가지의 tool 제공 (겉으로 보기엔 좋아보임)
-> 해당 도구들은 일반적인 라이브러리와 동급처리 X 
- langGaraph로 멋지게 여러 노드를 구성해서 만들었지만, 디버깅하는데 굉장히 시간과 비용이 들 수 있음 
- 디버깅이 굉장히 중요하다고 생각 - 얼마나 내가 코드를 surgery 할 수 있는 지점들이 있는 지(해부할 수 있는 포인트) 확인이 가능 
- 매직처럼 보이는 tool calling을 직접 확인할 수 있음. 그래프 구조를 만든 다음에 실행 가능한 코드로변환하는 작업이 있는데, 어떻게 함수 호출하면 좋고 어떻게 병행의 구조로 실행하면 좋고 등등의 계산이 가능한데, 에이전트 workflow의 최적화 도구로서 특정 노드로 돌아가서 실험해볼 수 있다고 봄 


* AI Agent를 잘 구성하기 위해 중요한 요소 
<img width="973" height="457" alt="image" src="https://github.com/user-attachments/assets/f06fb64a-22a7-41a8-9466-0160d94d178b" />

### 특화된 프레임워크 사용하는 이점? 
-> 그래프 구조를 만든 다음에 실행 가능한 코드로변환하는 작업이 있는데 그 과정에서 어떻게 함수 호출하면 좋고 어떻게 병행의 구조로 실행하면 좋고 등등의 계산이 쉽게 가능한데, 그러한 과정에서 
에이전트 workflow의 최적화 도구로 만들어 가는데 실험이 가능하다 (특정 노드로 돌아가서 실행해볼 수 도 있고) 
-> 잘 oraganized 생태계를 구성 
-> langsmith 괜찮음 
-> 히스토리 관리 유용, tracing도 잘 되고 등등 
-> 그래프 만들면 바로 배포가능하다는 점 (이식이 바로 가능하게끔 만들어놓음)
-> text split, chunking, retrieving 전략, model temperature 등등 하이퍼 파라미터 구성값이 굉장히 많은데 그런 것들 하나하나 대입하면서 쉽게 비교가 가능하다는 것도 이점 

* BUT, AI Agent는 그렇게 학습되었을 뿐이고, 마법은 아니라고 생각. 로지컬하게는 무한루프 돌면서 좀 더 쉽게 만들었다는 정도. 디버깅하기에 좀 어렵고 검증하는게 어려움 


### QnA 
- 개인적인 견해로는, 구현에 들어가는 시간은 굉장히 단축되었다고 생각. Agent workflow를 구성하는 건 어려운 건 아니라고 생각. 
대신에, 그걸 어떻게 디버깅할 것이냐에 대해서 생각해봤을 때 밑바닥부터 구현하는 게 중요하다고 생각이 들음. 
도구가 굉장히 많다보니 문서화가 잘 되어있지 않아보임. 기술부채가 많이 쌓이겠다고 생각 
tool 관련 라이브러리 provider들이 얼마나 실시간으로 대응을 잘 하는 지 중요할 것 같음 
ai시대가 도래하면서 되게 추상적으로 멀리서보면 굉장히 똑똑한 시스템이라고 생각할 수 있는데, 
정해놓은 특정 유즈케이스에 대해 잘 작동하도록 패키지되어있는 게 중요하다고 생각, 그렇게 패키지 상태로 잘 던져질 수 있으면 시간이 지나도 그 유스케이스에서 잘 작동하면 됨.
그게 굉장히 중요하다고 생각함. 그래서 llm 오픈소스 코드에 관심이 많음. 

