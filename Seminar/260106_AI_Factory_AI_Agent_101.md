(링크: https://www.youtube.com/watch?v=DIYT8hRLq2Y&t=1101s) 

(아직 정리하지 않음. 메모만)
---

### AI agent는 어떻게 작동하는가 ? 

* prompt engineering 
얼마나 지시를 정확하게 잘 내리느냐 
instruction following 

* context engineering
의사결정을 하기위해 잘 쌓여놓은 context를 얼마나 잘 정리하느냐
필요없는 정보를 버리거나, 중복제거, 압축, 요약, 가지치기등을 하는 걸 통해서 
dead, summarization, compression, pruning 



tool calling이 등장하면서 히든피스가 되었다고 생각된다
system prompt를 던져주고 내가 어떤 도구를 호풀할 수 있고 입력프롬프트를 처리하기 위해 내가 보유한 도구 중에 어떤 걸 호출해야 하는 지 
이러한 부분들이 학습이 되어있는 것
내부적으로 텍스트

텍스트일 뿐 
사용할 도구가 많다는 것은 AI모델이 헷갈릴 포인트를 줄 수 있음 

어떤 도구를 가지고 있는지에 대한 문맥이 있고 
함수이름 파싱 
llm이 생성한 파라미터 매핑시켜서 


context engineering 
기본적으로 모델이 의사결정을 내리기 위해 context길이를 얼마나 잘 관리하는 지가 굉장히 중요한 요점 

에이전트는 어떻게 평가할 것인가? 
에이전트 단위평가 

멀티에이전트가 나온 이유는 
자기가 맡은 고유의 영역 
난 이 컨텍스트만 바라보겠다 그 관련 도구 집합만 바라보겠다
일의 분업화를 위해 멀티 에이전트 시스템이 나왔다고 바라봄 

그래서 각각의 에이전트 단위로 평가하는 것도 하나의 방식일 수 있음 
도구 호출이 적절하게 잘 호출되었는지 평가 항목이 될 수도 있음 (도구단위 평가) 
평가 - 정량적(verification이 가능한) - hard evaluation /정성적 (검증이 불가능하지만 평가가 가능한) - soft evaluation
-> hard evaluation 을 많이 할 수 있다면 그게 제일 바람직하다고 하지만, hard evaluation 지표를 세우는 게 어려움  
-> 에이전트 시스템  
-> ground truth를 잘 정의하는게 굉장히 중요 
-> 최종 답변도 자연어이기에 평가하기가 어려운데 각 에이전트 단위로 평가하는 건 더 쉬울 수 있음 (단계별로 분해해서 평가를 하는 방법이 있는 것)
-> 

데이터가 몇 조개가 되는 것 

밑바닥부터 구현하는 에이전트 
langchain 커뮤니티가 외부적으로 볼 때 600여가지의 툴을 제공한다고 하지만 해당 툴들이 일반적인 시스템 수준은 아니라고 생각 

특확된 프레임워크의 장점: 기존에 보통 DAG 구조로만 흐름을 생성했엇음 

벤치마크 키워드 셋 
시스템의 강건성을 평가하기 위함 

사용자가 입력하는 자연어를 넣더라도 에이전트 시스템이 무리없이 잘 작동하느냐 



### 밑바닥부터 AI Agent 구현 왜?
* AI Agent를 잘 구성하기 위해 중요한 요소 
<img width="907" height="321" alt="image" src="https://github.com/user-attachments/assets/678cae58-ae2e-4110-8b63-88075ab7be91" />

