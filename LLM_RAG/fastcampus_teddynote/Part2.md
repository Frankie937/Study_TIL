## Part 2.  ì²´ì¸ íŒŒì´í”„ë¼ì¸ì˜ ê¸°ë³¸ ìš”ì†Œ

### ch1. í”„ë¡¬í”„íŠ¸

02. yaml íŒŒì¼ë¡œë¶€í„° í”„ë¡¬íŠ¸ í…œí”Œë¦¿ ë¡œë“œ(load_prompt)
  - í”„ë¡¬í”„íŠ¸ëŠ” YAML íŒŒì¼í˜•ì‹ìœ¼ë¡œ ì €ì¥í•´ë‘ê³  ê´€ë¦¬í•˜ëŠ” ê²ƒì„ ì¶”ì²œ!!

06. ì˜ˆì œ ì„ íƒê¸°(Example Selector)
  - example_selectorì˜ ê¸°ëŠ¥ - promptì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ì˜ˆì‹œë¥¼ kê°œ ë§Œí¼ ì¶”ì¶œí•˜ëŠ” ê¸°ëŠ¥
  â†’ ì˜ˆì‹œë¥¼ ë„ˆë¬´ ë§ì´ ë„£ì–´ë²„ë¦¬ë©´ ì…ë ¥ í† í°ì„ ë„ˆë¬´ ë§ì´ ì‚¬ìš©í•˜ê²Œ ë¨ (ë¹„ìš© ì¦ê°€) 
  â†’ ë¹„ìš©ì¸¡ë©´ ë¿ë§Œ ì•„ë‹ˆë¼, ë‹µë³€ ì–‘ì‹(ì˜ˆì‹œ)ë“¤ì´ ì—¬ëŸ¬ ë‹¤ì–‘í•˜ê²Œ ìˆì„í…ë° (ex-íšŒì˜ë¡ í˜•ì‹, ê¸°íšì•ˆ í˜•ì‹ ë“±ë“±) ê·¸ ì¤‘ì—ì„œ ìš”êµ¬ì‚¬í•­(ì§ˆë¬¸)ê³¼ ê°€ì¥ ìœ ì‚¬í•œ í˜•ì‹ì˜ ë‹µë³€ ì–‘ì‹ì„ ì°¸ê³ í•´ì„œ ë‹µë³€í•  ìˆ˜ ìˆê²Œë” ë§Œë“¤ì–´ ì£¼ëŠ” ìš©ë„ì´ê¸°ë„ í•¨!
![image](https://github.com/user-attachments/assets/bb335dfd-b1d5-4337-a969-5a2c297bfd49)

07. MaxMarginalRelevance(MMR) ì•Œê³ ë¦¬ì¦˜ 
  - ê¸°ì¡´ì— 06ë²ˆì—ì„œ ì‚¬ìš©í–ˆë˜ ì•Œê³ ë¦¬ì¦˜ SemanticSimilarityExampleSelectorëŠ” ë§ì´ ì•Œê³  ìˆëŠ” cosine similarityë¥¼ ì‚¬ìš©í•œ ì½”ì‚¬ì¸ìœ ì‚¬ë„ ê³„ì‚°ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê°€ì¥ ìœ ì‚¬í•œ ê²ƒì„ ë½‘ì•„ë‚´ëŠ” ì•Œê³ ë¦¬ì¦˜ ê¸°ë²•
  - MaxMarginalRelevance ì•Œê³ ë¦¬ì¦˜ì€ ì§ˆë¬¸ê³¼ ìœ ì‚¬ì„±ì´ ìˆìœ¼ë©´ì„œë„ ë‹¤ì–‘í•œ ì˜ˆì œë¥¼ ê°€ì ¸ì˜¤ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©! (ì¦‰, ê´€ë ¨ì„±ê³¼ ë‹¤ì–‘ì„± 2ê°€ì§€ ì¸¡ë©´ì„ ê³ ë ¤í•¨. ë¨¼ì € ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ í•­ëª©ì„ ì„ íƒí•˜ê³  ê·¸ ì´í›„ ê´€ë ¨ì„±ì´ ë†’ìœ¼ë©´ì„œ ê°€ì¥ ì°¨ë³„í™”ëœ í•­ëª©ë“¤ì„ ì°¾ì•„ ì„ íƒí•˜ëŠ” êµ¬ì¡° - ëŒë‹¤ê°’ì— ì˜í•´ ê´€ë ¨ì„±ê³¼ ì°¨ë³„ì„±ì„ ì¡°ì ˆ â†’ ëŒë‹¤ê°’ì´ í´ìˆ˜ë¡ ë‹¤ì–‘ì„±ì„, ì‘ì„ìˆ˜ë¡ ë‹¤ì–‘ì„±ì„ ë” ì¤‘ì‹œí•œë‹¤ê³  í•¨)
![image](https://github.com/user-attachments/assets/e7033981-f536-4558-bbcb-0612b9950e47)

08. ëª©ì ì— ë§ëŠ” ì˜ˆì œ ì„ íƒê¸°(CustomExampleSelector)
â†’  í…Œë””ë‹˜ì´ ë§Œë“œì‹  CustomExampleSelector
![image](https://github.com/user-attachments/assets/abd2351d-95cb-4e31-b17f-7772e0f873eb)
![image](https://github.com/user-attachments/assets/1c874359-f228-4368-843d-8b346b7221ec)
  â†’ ì € í´ë˜ìŠ¤ ë‚´ë¶€ë¥¼ ë³´ë©´ search_key ì¸ìë¥¼ ë”°ë¡œ ë§Œë“¤ì–´ì„œ, ì € ê°’ì´ instructionì´ë©´ instructionë¼ë¦¬ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ê³  inputì´ë©´ input ë¼ë¦¬ ìœ ì‚¬ë„ ì¸¡ì •í•´ì„œ ë‚˜ì˜¤ë„ë¡ í•¨! 
  â†’ ê¸°ì¡´ Example Selectorë“¤(SemanticSimilarityExampleSelector, MMR )ì€ ëª¨ë‘ ìœ ì‚¬ë„ ê³„ì‚°ì‹œ, instructionê³¼ inputì´ í•©ì‚°ëœ ìœ ì‚¬ë„ë¡œ ê³„ì‚°ë˜ì–´ì„œ ì˜ˆì‹œê°€ ì˜ ë‚˜ì˜¤ì§€ ì•Šì„ ë•Œê°€ ë§ì€ ë¬¸ì œê°€ ìˆìŒ

09. LangSmith - Hub
(https://smith.langchain.com/hub?organizationId=02a489e1-23b2-5f26-a131-f2851cc73a9c)
![image](https://github.com/user-attachments/assets/4e5e4ba7-c3e6-4076-916b-de6c540ffb00)
  â†’ ì˜ ì‘ì„±ëœ prompt ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ   
  â†’ ì˜¤ë¥¸ìª½ ë°”ì—ì„œ use caseë¡œ ê³¨ë¼ì„œ ì„ íƒí•˜ê³ , top viewë‚˜ top download í´ë¦­í•˜ë©´ ë³´í†µ rlm ê³„ì •ìœ¼ë¡œ ì˜¬ë ¤ì§„ promptê°€ ë§ìŒ. ê·¸ê²ƒë„ í‰ê· ì ìœ¼ë¡œ ì¢‹ì§€ë§Œ ê·¸ ë‹¤ìŒêº¼ ì¶”ì²œí•œë‹¤ê³  í•˜ì‹¬

![image](https://github.com/user-attachments/assets/b116aa89-a6b2-49ba-883d-9afbaa226c21)
  â†’  ì§ì ‘ ë³µì‚¬í•´ì„œ ì‚¬ìš©í•´ë„ ì¢‹ê³  
  â†’ ì €ë ‡ê²Œ langchain ì½”ë“œë¡œ ê°–ê³ ì˜¬ ìˆ˜ë„ ìˆìŒ
  
```python
prompt = hub.pull("rlm/rag-prompt:50442af1")
prompt
```
  â†’ íŠ¹ì • ë²„ì „ì„ : ì´í›„ë¡œ í•´ì‹œì½”ë“œ ì‘ì„±í•´ì„œ ë‹¤ë¥¸ ë²„ì „ìœ¼ë¡œ ê°–ê³ ì˜¬ ìˆ˜ë„ ìˆìŒ (commit ë²„íŠ¼ ëˆŒëŸ¬ë³´ë©´ ë²„ì „ë³„ í™•ì¸ ê°€ëŠ¥)
  â†’ ë˜í•œ, ìì‹ ì‹ ì´ ì‘ì„±í•œ promptë¥¼ hubì— ì—…ë¡œë“œë„ ê°€ëŠ¥! (ì•„ë˜ì½”ë“œ ì°¸ê³ )
```python
from langchain.prompts import ChatPromptTemplate
prompt = ChatPromptTemplate.from_template(
    "ì£¼ì–´ì§„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë¬¸ì¥ì„ ìš”ì•½í•˜ì„¸ìš”. ë‹µë³€ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”\n\nCONTEXT: {context}\n\nSUMMARY:"
)
prompt
from langchain import hub
# í”„ë¡¬í”„íŠ¸ë¥¼ í—ˆë¸Œì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.
hub.push("teddynote/simple-summary-korean", prompt)
```
** ë§Œì•½ ë‚´ê°€ ì‘ì„±í•œ promptë¥¼ privateí•˜ê²Œ ì—…ë¡œë“œ í•˜ê³  ì‹¶ë‹¤ë©´ â€˜Make Privateâ€™ ê¸°ëŠ¥ ì‚¬ìš© 
![image](https://github.com/user-attachments/assets/330c14ad-1474-433e-8555-197db7148b87)


### ch3. RAGì‹œì‘í•˜ê¸°

- 01~04 ë²ˆ ë‚´ìš©
#### EP01.Â [#RAG](https://www.youtube.com/hashtag/rag)Â ì˜ ë™ì‘ ê³¼ì • ì‰½ê²Œ ì´í•´í•˜ê¸°!
** ì„ë² ë”© ? 
ë¬¸ì„œì˜ ë‹¨ë½ â†’ ìˆ˜í•™ì ì¸ í‘œí˜„ ì¦‰ ì¢Œí‘œê³„ë¡œ ë³€ê²½ 
- ë¬¸ì„œ ì„ë² ë”© í”„ë¡œì„¸ìŠ¤ êµ¬ì¡°
ë¬¸ì„œ ë¡œë“œ > ë¬¸ì„œ split > ìª¼ê°œì§„ ë¬¸ì„œì˜ ë‹¨ë½ì„ ì„ë² ë”© (ìˆ˜í•™ì  í‘œí˜„, ì¢Œí‘œê³„ë¡œ ë³€í™˜) > ë²¡í„°DB ì €ì¥
(ex ë²¡í„°ë¥¼ ì‚¬ìš© - open ai ì„ë² ë”©ëª¨ë¸ 1536ì°¨ì›ì„ ì‚¬ìš© â†’ 1536ê°œì˜ ìˆ«ìë¡œ í‘œí˜„ëœë‹¤ëŠ” ì˜ë¯¸)

#### EP02. #RAG ì˜ ë™ì‘ê³¼ì • ì‰½ê²Œ ì´í•´í•˜ê¸°!(ì‹¤í–‰ë‹¨ê³„)
** ê²€ìƒ‰ê¸°(Retriever) ë‹¨ê³„ëŠ” Retrieval-Augmented Generation(RAG) ì‹œìŠ¤í…œì˜ ë‹¤ì„¯ ë²ˆì§¸ ë‹¨ê³„ë¡œ, ì €ì¥ëœ **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰**í•˜ëŠ” ê³¼ì •ì´ë‹¤. ì´ ë‹¨ê³„ëŠ” **ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ì •ë³´ë¥¼ ì‹ ì†í•˜ê²Œ ì°¾ì•„ë‚´ëŠ” ê²ƒ**ì´ ëª©í‘œì´ê³ , RAGì‹œìŠ¤í…œì˜ ì „ë°˜ì ì¸ ì„±ëŠ¥ê³¼ ì§ê²°ë˜ëŠ” ë§¤ìš° ì¤‘ìš”í•œ ê³¼ì •ì´ë‹¤! 

** ê²€ìƒ‰ê¸°ì— ì‚¬ìš©ë˜ëŠ” ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜ì´ ë§ìŒ (í‚¤ì›Œë“œ, ì˜ë¯¸ê²€ìƒ‰, í•˜ì´ë¸Œë¦¬ë“œ ì„œì¹˜ ë“±ë“±â€¦)
 ex) Sparse Retriever ('í‚¤ì›Œë“œ' ê²€ìƒ‰ì„ ì˜í•˜ëŠ” ê²€ìƒ‰ê¸°), Dense Retriever('ì˜ë¯¸ê²€ìƒ‰'ì„ ì˜í•˜ëŠ” ê²€ìƒ‰ê¸°) ë“± 

** ê²€ìƒ‰ê¸° ì†ë„ë„ ì¤‘ìš” (-> ì‘ë‹µì‹œê°„ ë‹¨ì¶•ì„ ìœ„í•´)

- ë™ì‘ë°©ì‹ (í•œë²ˆ ë” ë³µìŠµ)
    1. ì§ˆë¬¸ì˜ ë²¡í„°í™”: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë²¡í„° í˜•íƒœë¡œ ë³€í™˜(ì´ ê³¼ì •ì€ ì„ë² ë”© ë‹¨ê³„ì™€ ìœ ì‚¬í•œ ê¸°ìˆ  ì‚¬ìš©í•˜ì—¬ ì§„í–‰) ë³€í™˜ëœ ì§ˆë¬¸ ë²¡í„°ëŠ” í›„ì† ê²€ìƒ‰ ì‘ì—…ì˜ ê¸°ì¤€ì ìœ¼ë¡œ ì‚¬ìš© ë¨
    2. ë²¡í„° ìœ ì‚¬ì„± ë¹„êµ: ì €ì¥ëœ ë¬¸ì„œ ë²¡í„°ë“¤ê³¼ ì§ˆë¬¸ ë²¡í„°ì‚¬ì´ì˜ ìœ ì‚¬ì„±ì„ ê³„ì‚° (ì£¼ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„(cosine similarity), Max Marginal Relevance(MMR) ë“±ì˜ ìˆ˜í•™ì  ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰
    3. ìƒìœ„ ë¬¸ì„œ ì„ ì •: ê³„ì‚°ëœ ìœ ì‚¬ì„± ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ Nê°œì˜ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ì„ ì •í•¨. (ì´ ë¬¸ì„œë“¤ì€ ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš© ë¨ - í”„ë¡¬í””íŠ¸ì—ì„œ ì°¸ê³  contextë¡œì„œ) 
    4. ë¬¸ì„œ ì •ë³´ ë°˜í™˜: ì„ ì •ëœ ë¬¸ì„œë“¤ì˜ ì •ë³´ë¥¼ ë‹¤ìŒ ë‹¨ê³„(í”„ë¡¬í”„íŠ¸ ìƒì„±)ë¡œ ì „ë‹¬í•¨. ì´ ì •ë³´ì—ëŠ” ë¬¸ì„œì˜ ë‚´ìš©, ìœ„ì¹˜, ë©”íƒ€ë°ì´í„° ë“±ì´ í¬í•¨ë  ìˆ˜ ìˆìŒ 

** ì›ë˜ RAGë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ì„ ë•ŒëŠ”, ê¸°ë³¸ì ì¸ LLMì—ì„œëŠ” LLM ëª¨ë¸ì— ë„£ì–´ì£¼ëŠ” í”„ë¡¬í”„íŠ¸ì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ë§Œ ë„£ì—ˆì§€ë§Œ RAGë¥¼ ì‚¬ìš©í•˜ëŠ” ê±´ í”„ë¡¬í”„íŠ¸ì— contextë¥¼ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ í•¨ê»˜ ë„£ì–´ì£¼ëŠ” ê²ƒ
(-> ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•  ë•Œ, ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ contextë¡œ ì°¸ê³ í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ë¼ëŠ” ì˜ë¯¸- ì´ê²Œ RAGì˜ í•µì‹¬- contextë¥¼ llmì—ê²Œ ì£¼ëŠ” ê²ƒ!!) 

#### EP03. #PDF ë¬¸ì„œê¸°ë°˜ QA #RAG êµ¬ì¶•í•˜ê¸°

- ë¬¸ì„œë¡œë“œ
    - ë©”íƒ€ë°ì´í„°ëŠ” ì–´ë–¤ ë¬¸ì„œë¡œë”ë¥¼ ì‚¬ìš©í–ˆëŠëƒì— ë”°ë¼ ë‹¤ë¥´ë‹¤. (**ë©”íƒ€ë°ì´í„°ë¥¼ ì˜ í™œìš©í•´ì„œ ë¬¸ì„œë¥¼ ì¶”ì¶œí•  ë•Œ í•„í„°ë§í•˜ê±°ë‚˜ ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë©”íƒ€ë°ì´í„°ì— ëŒ€í•œ ì •ë³´ì™€ êµ¬ì¡°ë¥¼ ë¡œë”ì— ë”°ë¼ ì˜ í™•ì¸í•˜ê³  í™œìš©í•˜ëŠ” ê²ƒ ì¤‘ìš”ìš”)
    ex) PyMuPDFLoader
![image](https://github.com/user-attachments/assets/fabcb97e-1d8f-4a44-af8a-365a9148cf9c)

```python
# ë‹¨ê³„ 1: ë¬¸ì„œ ë¡œë“œ(Load Documents)
loader = PyMuPDFLoader("data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf")
docs = loader.load()
```

- ë¬¸ì„œ ë¶„í• 
    - RecursiveCharacterTextSplitter ë¥¼ ë²”ìš©ì ìœ¼ë¡œ ë§ì´ ì‚¬ìš©
    - chunk_size ì •í•  ë•Œ íŒ: ë¬´ì¡°ê±´ í¬ê²Œ ì„¤ì •í•œë‹¤ê³  ì¢‹ì€ ê²ƒ ì•„ë‹˜! í•´ë‹¹ ë¬¸ì„œì˜ íŠ¹ì„±ì— ë”°ë¼ ê°™ì€ ë§¥ë½ì´ ì´ì–´ì§€ëŠ” ë¬¸ë‹¨ì´ë‚˜ ë‹¨ë¼ì˜ ê¸€ì ìˆ˜ ë‹¨ìœ„ë¥¼ ì–´ëŠì •ë„ íŒŒì•…í•˜ê³  ì •í•´ì£¼ëŠ” ê²Œ ë² ìŠ¤íŠ¸ì¸ë°, ê·¸ëŸ¬ë‚˜ ê·¸ ê¸€ììˆ˜ê°€ í•­ìƒ ì¼ì •í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ëŒ€ëµì ìœ¼ë¡œ ë„£ì–´ì¤„ ìˆ˜ ë°–ì—ëŠ” ì—†ìŒâ€¦
    
    ```python
    # ë‹¨ê³„ 2: ë¬¸ì„œ ë¶„í• (Split Documents)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
    split_documents = text_splitter.split_documents(docs)
    ```
    
- ì„ë² ë”©

```python
# ë‹¨ê³„ 3: ì„ë² ë”©(Embedding) ìƒì„±
embeddings = OpenAIEmbeddings()
```

- ë²¡í„° DB ë° ì €ì¥

```python
# ë‹¨ê³„ 4: DB ìƒì„±(Create DB) ë° ì €ì¥
# ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)
```

- Retriever ìƒì„±

```python
# ë‹¨ê³„ 5: ê²€ìƒ‰ê¸°(Retriever) ìƒì„±
# ë¬¸ì„œì— í¬í•¨ë˜ì–´ ìˆëŠ” ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìƒì„±í•©ë‹ˆë‹¤.
retriever = vectorstore.as_retriever()
```

- Prompt ìƒì„±

```python

# ë‹¨ê³„ 6: í”„ë¡¬í”„íŠ¸ ìƒì„±(Create Prompt)
# í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
prompt = PromptTemplate.from_template(
    """You are an assistant for question-answering tasks. 
Use the following pieces of retrieved context to answer the question. 
If you don't know the answer, just say that you don't know. 
Answer in Korean.

#Context: 
{context}

#Question:
{question}

#Answer:"""
)
```

- LLM ëª¨ë¸ ìƒì„±

```python
# ë‹¨ê³„ 7: ì–¸ì–´ëª¨ë¸(LLM) ìƒì„±
# ëª¨ë¸(LLM) ì„ ìƒì„±í•©ë‹ˆë‹¤.
llm = ChatOpenAI(model_name="gpt-4o", temperature=0)
```

- Chain ìƒì„±

```python
# ë‹¨ê³„ 8: ì²´ì¸(Chain) ìƒì„±
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
```

â†’ Chain ì‹¤í–‰

```python
# ì²´ì¸ ì‹¤í–‰(Run Chain)
# ë¬¸ì„œì— ëŒ€í•œ ì§ˆì˜ë¥¼ ì…ë ¥í•˜ê³ , ë‹µë³€ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
question = "ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ AI ì˜ ì´ë¦„ì€?"
response = chain.invoke(question)
print(response)

# stream í˜•ì‹ìœ¼ë¡œ ë‚˜ì˜¤ê²Œ í•˜ë ¤ë©´ 
import langchain_teddynote.messages import stream_response

question = "ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ AI ì˜ ì´ë¦„ì€?"
response = chain.stream(question)
stream_responese(response)
```

** LangSmithê°€ ì¤‘ìš”í•œ ì´ìœ ?

ê¸°ì¡´ì— ë‹µë³€ì´ ì˜ëª»ë‚˜ì™”ì„ ë•Œ, ë‹µë³€ë§Œ ë‚˜ì˜¤ê¸°ì— í•´ë‹¹ ì›ì¸ì´ë‚˜ ë¬¸ì œë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ì—ˆìŒ 

ê·¸ëŸ¬ë‚˜ LangSmithëŠ” ì´ë ‡ê²Œ ì°¸ê³ í•œ ë¬¸ì„œë“¤ì´ ëª‡ ê°œê°€ ìˆì—ˆê³  ì–´ë–¤ ë‚´ìš©ë“¤ì´ì—ˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆê²Œ í•´ì£¼ê¸°ì— ì–´ë””ì„œ ì˜ëª»ë˜ì—ˆë˜ ê±´ì§€ ì›ì¸ íŒŒì•… ë° ë¶„ì„ì´ ê°€ëŠ¥í•´ì§ 

ì°¸ê³ í•  ë„íë¨¼íŠ¸ë“¤ì´ ì˜ëª» ì¶”ì¶œëœ ê²ƒì´ë¼ë©´, ê²€ìƒ‰ê¸°ê°€ ì˜ëª» ëœ ê²ƒì´ê¸°ì— ê²€ìƒ‰ê¸° ë¶€ë¶„ì„ ìˆ˜ì •ì„ í•´ì¤˜ì•¼ í•˜ê±°ë‚˜ ì•„ë‹ˆë©´, ê²€ìƒ‰ê¸° ì•Œê³ ë¦¬ì¦˜ì˜ ë¬¸ì œê°€ ì•„ë‹ˆë¼ ë¬¸ì„œë¥¼ ì˜ëª» ë¡œë“œí–ˆì„ ìˆ˜ë„ ìˆê³ , splitì—ì„œ ì˜ëª»ëœ ê±¸ìˆ˜ë„ ìˆê³ , ì„ë² ë”©ì´ ì˜ëª»ë  ìˆ˜ ë„, DBì„ íƒì´ ì˜ëª»ë˜ì—ˆì„ ìˆ˜ë„ ìˆë‹¤â€¦ 5ê°€ì§€ ë¬¸ì œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë´ì•¼ í•œë‹¤!!!! 

ê·¸ë ‡ê¸°ì— ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ì˜ í•´ê²°í•˜ê¸° ìœ„í•´ì„œëŠ” í•˜ë‚˜í•˜ë‚˜ ë‹¨ê³„ë§ˆë‹¤ ì„¸ë¶€ì ìœ¼ë¡œ í™•ì¸í•˜ê³  ì´í•´í•˜ê³  ê³µë¶€í•´ì•¼ í•  í•„ìš”ê°€ ìˆëŠ” ê²ƒ !!!(ê·¸ë˜ì„œ ê¸°ë³¸ê¸°ë„ êµ‰ì¥íˆ ì¤‘ìš”)
![image](https://github.com/user-attachments/assets/b522a643-8e76-422f-8b76-29437d30ae1a)



 ** ì•„ë˜ì™€ ê°™ì´, ë‹µë³€ì— ì°¸ê³ í•œ ë¬¸ì„œ í˜ì´ì§€ë²ˆí˜¸ ì¶”ê°€í•˜ëŠ” ë°©ë²•!! 
![image](https://github.com/user-attachments/assets/1f652791-c633-4ac8-a019-8a03f346af56)
â†’ ë‹µë³€ì—ì„œ ì–´ë–¤ í˜ì´ì§€ ì°¸ê³ í–ˆëŠ”ì§€ ì •ë³´ ì¶”ê°€í•´ì„œ ë„£ì–´ë‹¬ë¼ëŠ” ê²ƒì„ promptë¡œ ì¶”ê°€í•´ì„œ ë³€ê²½ 

â€œYou must include â€˜pageâ€™ number in your answer.â€
![image](https://github.com/user-attachments/assets/1d534300-35bd-4cab-a846-174162001d39)

â†’ ì´ê²Œ ê°€ëŠ¥í•œ ì´ìœ ëŠ” ì‚¬ìš©í•œ pdf ë¡œë”, PyMuPDFLoaderì—ì„œ metadataì— page ë²ˆí˜¸ê°€ ìˆê¸° ë•Œë¬¸ !!!
![image](https://github.com/user-attachments/assets/4ba85a06-433b-44c4-9570-46fc18392699)

** promptì—ì„œ ì—¬ëŸ¬ ê°œì˜ ë³€ìˆ˜ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì„ ë•Œ prompt.partialì„ ì‚¬ìš©í•˜ê¸° 
ex) prompt-maker.yaml íŒŒì¼ì—ì„œ  ë³´ì—¬ì§€ëŠ” ê²ƒì²˜ëŸ¼ {task} , {question} 2ê°œì˜ ë³€ìˆ˜ê°€ ì…ë ¥ë³€ìˆ˜ë¡œ ë°›ì•„ì•¼ í•˜ëŠ” prompt êµ¬ì¡°
![image](https://github.com/user-attachments/assets/69cdd026-963e-47f2-b881-f90e0a7559e8)
![image](https://github.com/user-attachments/assets/57b457f8-e534-4afb-aa64-dd0afbb7ab6f)

â†’ prompt.partial ì„ ì´ìš©í•´ì„œ ë³€ìˆ˜ë¥¼ ì¶”ê°€ ì²˜ë¦¬ í•  ìˆ˜ ìˆìŒ 

- 08ë²ˆ ë‚´ìš©
-01_PDF.pyì—ì„œ ì‚¬ìš©ë˜ëŠ” pdf-rag.yaml íŒŒì¼ì—ì„œ prompt ì£¼ìš”í•œ íŒ!! (ì¶œì²˜ ê¸°ë¡ & ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í‘œ í˜•ì‹)
  ![image](https://github.com/user-attachments/assets/2f657d37-e90a-4e32-8b53-5d884d69955a)


### ch4. ì¶œë ¥íŒŒì„œ(Output Parser)
- 01ë²ˆ - PydanticOutputParser
    - ì£¼ìš” ì—”í‹°í‹° ì¶”ì¶œì„ ì˜ í• ë ¤ë©´ descriptionì„ ì˜ ì‘ì„±í•˜ëŠ” ê²Œ ì¤‘ìš”í•˜ë‹¤!!
```python
from langchain_core.pydantic_v1 import BaseModel, Field

# ì´ë©”ì¼ ë³¸ë¬¸ìœ¼ë¡œë¶€í„° ì£¼ìš” ì—”í‹°í‹° ì¶”ì¶œ 
class EmailSummary(BaseModel):
    person: str = Field(description="ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒ")
    company: str = Field(description="ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒì˜ íšŒì‚¬ ì •ë³´")
    email: str = Field(description="ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë©”ì¼ ì£¼ì†Œ")
    subject: str = Field(description="ë©”ì¼ ì œëª©")
    summary: str = Field(description="ë©”ì¼ ë³¸ë¬¸ì„ ìš”ì•½í•œ í…ìŠ¤íŠ¸")
    date: str = Field(description="ë©”ì¼ ë³¸ë¬¸ì— ì–¸ê¸‰ëœ ë¯¸íŒ… ë‚ ì§œì™€ ì‹œê°„")
```

- 10ë²ˆ - ì—´ê±°í˜• ì¶œë ¥íŒŒì„œ 
â†’ LLMìœ¼ë¡œë¶€í„° ì„ íƒì§€ë¥¼ ì£¼ê³  ê·¸ ì¤‘ì— ë‹µë³€ì„ ë°›ê³  ì‹¶ì„ ê²½ìš°ì— ìœ ìš©í•œ ì¶œë ¥íŒŒì„œ!

** ë‹µë³€ìœ¼ë¡œ ë¬¸ìì—´ë¡œ ë°›ì§€ ì•Šê³  Class ê°ì²´ë¡œ ë°›ìœ¼ë©´ ì¢‹ì€ ì ì´ ì •í˜•í™” ë˜ì–´ìˆì–´ì„œ ê°’ì„ keyë¡œ ì‰½ê²Œ êº¼ë‚¼ ìˆ˜ ìˆê³ 

### ch5. ì¶œë ¥íŒŒì„œ í™œìš© í”„ë¡œì íŠ¸

- chainì„ 2ê°œ ìƒì„± í•˜ê³  ê²€ìƒ‰ê¸°ëŠ¥ ì‚¬ìš©(SerpAPI í™œìš©)í•˜ì—¬ ë§Œë“œëŠ” í”„ë¡œì íŠ¸
    - ê¸°ëŠ¥ 3ê°€ì§€
        - ì´ë©”ì¼ì„ íŒŒì‹±í•˜ëŠ” chain ìƒì„±
        - ë³´ë‚¸ ì‚¬ëŒì˜ ì¶”ê°€ì •ë³´ ìˆ˜ì§‘ (ê²€ìƒ‰ê¸°ëŠ¥ ì‚¬ìš©)
        - ì´ë©”ì¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
```python
import os
from dotenv import load_dotenv
import streamlit as st
from langchain_core.messages.chat import ChatMessage
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.output_parsers import PydanticOutputParser
from langchain_openai import ChatOpenAI
from langchain_community.utilities import SerpAPIWrapper
from langchain_teddynote.prompts import load_prompt

# ê²€ìƒ‰ì„ ìœ„í•œ API KEY ì„¤ì •
os.environ["SERPAPI_API_KEY"] = (
    "[e76de14ee240e0051ed8bb05d5db568dd1dc9cfcaa2b51fd83613829a85bf244"
)
# keyê°’ì€ https://serpapi.com/manage-api-key ì—ì„œ í™•ì¸í•˜ê¸° 

# ì´ë©”ì¼ ë³¸ë¬¸ìœ¼ë¡œë¶€í„° ì£¼ìš” ì—”í‹°í‹° ì¶”ì¶œ (description ì˜ ì‘ì„±í•˜ëŠ” ê²Œ ì¤‘ìš”)
class EmailSummary(BaseModel):
    person: str = Field(description="ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒ")
    company: str = Field(description="ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒì˜ íšŒì‚¬ ì •ë³´")
    email: str = Field(description="ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë©”ì¼ ì£¼ì†Œ")
    subject: str = Field(description="ë©”ì¼ ì œëª©")
    summary: str = Field(description="ë©”ì¼ ë³¸ë¬¸ì„ ìš”ì•½í•œ í…ìŠ¤íŠ¸")
    date: str = Field(description="ë©”ì¼ ë³¸ë¬¸ì— ì–¸ê¸‰ëœ ë¯¸íŒ… ë‚ ì§œì™€ ì‹œê°„")

# API KEY ì •ë³´ë¡œë“œ
load_dotenv()

st.title("Email ìš”ì•½ê¸° ğŸ’¬")

# ì²˜ìŒ 1ë²ˆë§Œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì½”ë“œ
if "messages" not in st.session_state:
    # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ìš©ë„ë¡œ ìƒì„±í•œë‹¤.
    st.session_state["messages"] = []

# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    # ì´ˆê¸°í™” ë²„íŠ¼ ìƒì„±
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")

# ì´ì „ ëŒ€í™”ë¥¼ ì¶œë ¥
def print_messages():
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)

# ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¶”ê°€
def add_message(role, message):
    st.session_state["messages"].append(ChatMessage(role=role, content=message))

# ì²´ì¸ ìƒì„±
def create_email_parsing_chain():
    # PydanticOutputParser ìƒì„±
    output_parser = PydanticOutputParser(pydantic_object=EmailSummary)

    prompt = PromptTemplate.from_template(
        """
    You are a helpful assistant. Please answer the following questions in KOREAN.

    #QUESTION:
    ë‹¤ìŒì˜ ì´ë©”ì¼ ë‚´ìš© ì¤‘ì—ì„œ ì£¼ìš” ë‚´ìš©ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.

    #EMAIL CONVERSATION:
    {email_conversation}

    #FORMAT:
    {format}
    """
    )

    # format ì— PydanticOutputParserì˜ ë¶€ë¶„ í¬ë§·íŒ…(partial) ì¶”ê°€
    prompt = prompt.partial(format=output_parser.get_format_instructions())

    # ì²´ì¸ ìƒì„±
    chain = prompt | ChatOpenAI(model="gpt-4-turbo") | output_parser

    return chain

def create_report_chain():
    prompt = load_prompt("prompts/email.yaml", encoding="utf-8")

    # ì¶œë ¥ íŒŒì„œ
    output_parser = StrOutputParser()

    # ì²´ì¸ ìƒì„±
    chain = prompt | ChatOpenAI(model="gpt-4-turbo") | output_parser

    return chain

# ì´ˆê¸°í™” ë²„íŠ¼ì´ ëˆŒë¦¬ë©´...
if clear_btn:
    st.session_state["messages"] = []

# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
print_messages()

# ì‚¬ìš©ìì˜ ì…ë ¥
user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

# ë§Œì•½ì— ì‚¬ìš©ì ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´...
if user_input:
    # ì‚¬ìš©ìì˜ ì…ë ¥
    st.chat_message("user").write(user_input)

    # 1) ì´ë©”ì¼ì„ íŒŒì‹±í•˜ëŠ” chain ì„ ìƒì„±
    email_chain = create_email_parsing_chain()
    # email ì—ì„œ ì£¼ìš” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì²´ì¸ì„ ì‹¤í–‰
    answer = email_chain.invoke({"email_conversation": user_input})

    # 2) ë³´ë‚¸ ì‚¬ëŒì˜ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘(ê²€ìƒ‰)
    params = {"engine": "google", "gl": "kr", "hl": "ko", "num": "3"}  # ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
    search = SerpAPIWrapper(params=params)  # ê²€ìƒ‰ ê°ì²´ ìƒì„±
    search_query = f"{answer.person} {answer.company} {answer.email}"  # ê²€ìƒ‰ ì¿¼ë¦¬
    search_result = search.run(search_query)  # ê²€ìƒ‰ ì‹¤í–‰
    search_result = eval(search_result)  # list í˜•íƒœë¡œ ë³€í™˜

    # ê²€ìƒ‰ ê²°ê³¼(í•©ì¹˜ê¸°)
    search_result_string = "\n".join(search_result)

    # 3) ì´ë©”ì¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
    report_chain = create_report_chain()
    report_chain_input = {
        "sender": answer.person,
        "additional_information": search_result_string,
        "company": answer.company,
        "email": answer.email,
        "subject": answer.subject,
        "summary": answer.summary,
        "date": answer.date,
    }

    # ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
    response = report_chain.stream(report_chain_input)
    with st.chat_message("assistant"):
        # ë¹ˆ ê³µê°„(ì»¨í…Œì´ë„ˆ)ì„ ë§Œë“¤ì–´ì„œ, ì—¬ê¸°ì— í† í°ì„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥í•œë‹¤.
        container = st.empty()

        ai_answer = ""
        for token in response:
            ai_answer += token
            container.markdown(ai_answer)

    # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•œë‹¤.
    add_message("user", user_input)
    add_message("assistant", ai_answer)

```

- email.yaml íŒŒì¼
```yaml
_type: "prompt"
template: |
  ë‹¹ì‹ ì€ ì´ë©”ì¼ì˜ ì£¼ìš” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš”ì•½ ì •ë¦¬í•´ ì£¼ëŠ” ì „ë¬¸ê°€ ì…ë‹ˆë‹¤.
  ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë‹¤ìŒì˜ ì´ë©”ì¼ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œ í˜•ì‹ì˜ ìš”ì•½ì„ ì‘ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
  ì£¼ì–´ì§„ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–‘ì‹(format)ì— ë§ì¶”ì–´ ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.

  #Information:
  - Sender: {sender}
  - Additional Information about sender: {additional_information}
  - Company: {company}
  - Email: {email}
  - Subject: {subject}
  - Summary: {summary}
  - Date: {date}

  #Format(in markdown format):
  ğŸ™‡â€â™‚ï¸ ë³´ë‚¸ ì‚¬ëŒ:
  - (ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë¦„, íšŒì‚¬ ì •ë³´)

  ğŸ“§ ì´ë©”ì¼ ì£¼ì†Œ:
  - (ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë©”ì¼ ì£¼ì†Œ)

  ğŸ˜ ë³´ë‚¸ ì‚¬ëŒê³¼ ê´€ë ¨í•˜ì—¬ ê²€ìƒ‰ëœ ì¶”ê°€ ì •ë³´:
  - (ê²€ìƒ‰ëœ ì¶”ê°€ ì •ë³´)

  âœ… ì£¼ìš” ë‚´ìš©:
  - (ì´ë©”ì¼ ì œëª©, ìš”ì•½)

  â° ì¼ì •:
  - (ë¯¸íŒ… ë‚ ì§œ ë° ì‹œê°„)

  #Answer:
input_variables: ["sender", "additional_information", "company", "email", "subject", "summary", "date"]
```

### ch6. ëª¨ë¸(Model)

05. í† í° ì‚¬ìš©ëŸ‰ í™•ì¸  get_openai_callback 

```python
# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼
from dotenv import load_dotenv

# API KEY ì •ë³´ë¡œë“œ
load_dotenv()
from langchain.callbacks import get_openai_callback
from langchain_openai import ChatOpenAI

# ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
llm = ChatOpenAI(model_name="gpt-4o") 

# callbackì„ ì‚¬ìš©í•˜ì—¬ ì¶”ì í•©ë‹ˆë‹¤.
with get_openai_callback() as cb:
    result = llm.invoke("ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?")
    result = llm.invoke("ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?")
    print(f"ì´ ì‚¬ìš©ëœ í† í°ìˆ˜: \t\t{cb.total_tokens}")
    print(f"í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ëœ í† í°ìˆ˜: \t{cb.prompt_tokens}")
    print(f"ë‹µë³€ì— ì‚¬ìš©ëœ í† í°ìˆ˜: \t{cb.completion_tokens}")
    print(f"í˜¸ì¶œì— ì²­êµ¬ëœ ê¸ˆì•¡(USD): \t${cb.total_cost}")
```

09. HuggingFace Dedicated Endpointë¥¼ í™œìš©í•œ ë¡œì»¬ëª¨ë¸ ì›ê²© í˜¸ìŠ¤íŒ… 

â†’ í…Œë””ë‹˜ë„ ì •ë§ ì¢‹ì•„í•˜ëŠ” ì„œë¹„ìŠ¤ë¼ê³  í•˜ì‹¬

â†’ ë¡œì»¬ ëª¨ë¸ì„ í˜¸ìŠ¤íŒ…í•˜ëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ë¼ê³  í•˜ì‹¬ 

â†’ ë¹„ìš©ë„ ê°€ì„±ë¹„ ì¢‹ì€ GPU ê³ ë¥¼ ìˆ˜ ìˆê³ (**suggested í•˜ëŠ”) ì‚¬ìš©í•˜ê¸° ì‰½ê²Œ ë˜ì–´ìˆê¸°ì—, ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í•´ë³¼ ë•Œ ì¢‹ì€ ì„œë¹„ìŠ¤ë¼ê³  ìƒê°í•¨ !! 

 

1. HuggingFace Local ëª¨ë¸ 

â†’ ê¸°ì¡´, 8ë²ˆì€ í—ˆê¹…í˜ì´ìŠ¤ì˜ ì„œë²„ì— ì˜¬ë ¤ì ¸ìˆëŠ” ëª¨ë¸ ì¤‘ inference api ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ëª¨ë¸ì„ (í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ í˜¸ìŠ¤íŒ…í•˜ëŠ” êµ¬ì¡°) ë¡œì»¬ pcì—ì„œ ëŒë ¤ë³¸ ê²ƒì´ê³ / 9ë²ˆì€ í—ˆê¹…í˜ì´ìŠ¤ì˜ ì„œë²„ì— ì˜¬ë ¤ì ¸ ìˆëŠ” ëª¨ë¸ ì¤‘ inference api ê¸°ëŠ¥ì„ ì œê³µí•˜ì§€ ì•Šì§€ë§Œ endpoint url ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ëª¨ë¸ì„ (í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ í˜¸ìŠ¤íŒ…í•˜ëŠ” êµ¬ì¡°) ë¡œì»¬ pcì—ì„œ ëŒë ¤ ë³¸ ê²ƒ 

â†’ ì´ë²ˆ 10ë²ˆ ê°•ì˜ì—ì„œëŠ” í—ˆê¹…í˜ì´ìŠ¤ì— ì˜¬ë ¤ì ¸ ìˆëŠ” ì˜¤í”ˆ ëª¨ë¸ì„ ìš°ë¦¬ ë¡œì»¬pcì— ë‹¤ìš´ë¡œë“œ ë°›ì•„ì„œ ì¶”ë¡ í•˜ëŠ” ê³¼ì •ì„ ë³¼ ì˜ˆì •!! (â†’ ìš°ë¦¬ ê°ìì˜ ë¡œì»¬ PC ì‚¬ì–‘ì´ ì¤‘ìš”í•´ì§â€¦ ê·¸ë¡œë¯€ë¡œ ì‚¬ì–‘ì´ ì¢‹ì§€ ì•Šìœ¼ë©´ ì¶”ë¡ í•˜ëŠ” ê³¼ì •ì—ì„œ ouput í† í°ì´ ì¶œë ¥ë˜ëŠ” ê²Œ êµ‰ì¥íˆ ëŠë¦¬ê±°ë‚˜ gpuê°€ ì—†ë‹¤ë©´ ì•„ì˜ˆ êµ¬ë™ì´ ì•ˆë  ìˆ˜ë„..ã… ã…  â†’ ê·¸ë˜ì„œ, gpuê°€ ì„¤ì •ì´ ë˜ì–´ìˆì–´ì•¼ í•˜ê³  windowë¥¼ ì“¸ ê²½ìš° cuda ì„¤ì •ì´ ë˜ì–´ìˆì–´ì•¼ í•¨) 

### ch7. ëª¨ë¸í™œìš© í”„ë¡œì íŠ¸

03. [í”„ë¡œì íŠ¸] Ollama ëª¨ë¸ì„ ì‚¬ìš©í•œ RAG 

â†’ ëª¨ë¸ë§ˆë‹¤ í•™ìŠµ ì‹œí‚¨ í”„ë¡¬í”„íŠ¸ê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ëª¨ë¸ì— ë§ê²Œ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•´ì£¼ëŠ” ê²Œ ì¤‘ìš”!
