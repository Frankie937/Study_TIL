#### (**llm관련 오픈채팅방) OOM 이슈 관련 문의 답변 정리 


Q: rtx4090 x2개로 gemma2 27b sft파인 튜닝을 진행하고 있습니다. 근데 특정 스탭만 되면 잘 되던 학습이 OOM이 발생하며 학습이 중단되는 현상이 있습니다.
4bit양자화 , 학습시 배치 1, 로라 타겟 모듈 지정 x, 로라의 r=1로 지정해서 최대한 gpu사용을 줄여서 진행하고 있는데, 궁금한건 특정 스탭에서 왜 갑자기 6기가 이상의 추가적인 gpu램을 필요로 하는지 궁금합니다.
이와 같은 현상을 경험하신 분 있을까요?

A1: 캐싱이랑 학습 토큰이 긴 내용이 들어가서 그럴 가능성이 큽니다. 학습 전에 1배치 기준 스텝별 학습 토큰 길이를 통계치 내려서 과한 토큰 수가 있는지 확인해보세요.
현재 시스템에서 가장 많은 학습토큰 수를 알아내는 방법은
1. 직접 계산량을 측정한다.
2. 직접 계산이 힘들다면, 샘플 데이터를 직접 만들어 length를 고정해 100개 정도를 만들어서 학습 테스트를 진행한다.
