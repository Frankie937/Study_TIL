 ### Ilya Sutskever의 2025년 11월 Dwarkesh Podcast 인터뷰


* 주요 내용 요약
스케일링의 시대가 끝나고 연구의 시대로
Ilya는 AI 발전을 **2012-2020년(연구의 시대) → 2020-2025년(확장의 시대) → 2025년 이후(새로운 연구의 시대)**로 구분합니다. "확장(scaling)"은 단 한 단어로 무엇을 해야 할지 알려주는 강력한 개념이었지만, 이제는 사전 학습 데이터가 고갈되고 규모가 너무 커져서 단순히 "100배 더 늘리면 모든 게 변혁될 것"이라는 믿음이 현실적이지 않습니다.
​
* 모델의 불균형성 문제
현재 AI 모델들은 평가(evals) 점수는 높지만 실제 작업에서는 기대에 못 미치는 괴리를 보입니다. Ilya는 이를 "바이브 코딩" 예시로 설명합니다 - 모델이 버그를 고치려다 새 버그를 만들고, 다시 원래 버그로 돌아가는 순환.

​* 원인 분석:
  - RL 훈련이 모델을 특정 평가 지표에 과최적화(overfitting)시킴
  - 연구자들이 평가 지표에서 영감을 받아 RL 환경을 설계하면서 발생하는 "진짜 보상 해킹"
  - 모델의 실제 일반화 능력 부족

* 경쟁 프로그래밍 비유: 1만 시간 경쟁 프로그래밍만 연습한 학생 vs 100시간만 연습한 학생 - 후자가 실제 커리어에서 더 잘할 것입니다. 현재 모델들은 전자처럼 훈련되고 있습니다.
​
* 인간의 일반화 능력과 "It" 팩터
Ilya는 사전 학습이 막대한 양의 자연스러운 데이터를 제공하지만, 인간이 훨씬 적은 데이터로도 더 깊이 있고 신뢰성 있게 학습하는 이유를 설명하려 합니다. 두 번째 학생에게는 "그것(it)"이 있다고 표현하는데, 이는 단순한 사전 학습이 아닌 더 나은 기계 학습 능력을 의미합니다.

* ​감정과 가치 함수
인간의 감정은 진화가 부여한 가치 함수로 작용합니다. 감정 처리 능력을 잃은 뇌손상 환자는 양말 선택에 몇 시간이 걸리고 재무 결정을 못 내리게 됩니다.
​
* 가치 함수의 중요성:
  - 강화학습에서 궤적 끝까지 기다리지 않고 중간 단계에서 보상 신호 제공
  - DeepSeek R1은 궤적 공간이 너무 넓다고 했지만, Ilya는 "딥러닝이 못 할 건 없다"고 반박
  - 인간의 가치 함수는 진화에 의해 하드코딩된 감정에 의해 조절되며, 이것이 인간이 효과적으로 활동하는 데 핵심
​
* 진화의 미스터리: 진화가 어떻게 고차원적 사회적 욕구(평판, 사회적 승인 등)를 유전자에 인코딩했는지는 여전히 미스터리입니다. 이는 단순한 저차원 신호(냄새, 맛)와 달리 뇌 전체의 복잡한 계산이 필요한 개념들입니다.
​
* 확장에서 연구로의 전환
사전 학습의 특징:
   - 어떤 데이터를 넣을지 고민할 필요 없음 - 답은 "모든 것"
   - 양이 엄청나게 많고 자연스러운 데이터
   - 하지만 Gemini 같은 경우를 제외하면 곧 데이터 고갈
​
RL의 현재:
   - 사전 학습보다 더 많은 컴퓨팅 소비
   - 하지만 단순히 "확장"이 아니라 "자원을 생산적으로 쓰고 있는가?" 질문해야 함
​
* 인간이 모델보다 일반화를 잘하는 이유
표본 효율성 문제: 시각, 청각, 움직임은 진화적 사전 지식 덕분일 수 있지만, 언어, 수학, 코딩에서도 인간이 더 나은 이유는 무엇일까요?
  > Ilya의 답변: 최근까지 존재하지 않았던 영역에서 인간이 뛰어난 능력을 보인다면, 이는 "더 나은 기계 학습" 능력을 가지고 있다는 징후입니다. 하지만 구체적 방법에 대해서는 "불행히도 우리는 모든 머신러닝 아이디어를 자유롭게 논의할 수 있는 세상에 살고 있지 않습니다"라며 답변을 회피했습니다.
​
10대 운전자의 예: 검증 가능한 보상 없이도 가치 함수 덕분에 빠르게 학습합니다. 인간의 가치 함수는 매우 견고합니다.
​
SSI(Safe Superintelligence)의 비전
초지능으로 직행(Straight Shot)하기:
   - 장점: 일상적 시장 경쟁에서 격리되어 연구에 집중 가능
   - 단점: 강력한 AI를 세상에 보여주는 것의 가치 상실
   - AI를 소통하는 것(에세이가 아닌 실제 AI)의 중요성
​
* SSI의 모델은 지속적 학습:
   - 초지능은 "모든 직업을 수행할 수 있는 완성된 정신"이 아님
   - 대신 **"모든 직업을 배울 수 있는 정신"**을 목표로 함
   - 배포 자체가 학습 과정을 포함하는 프로세스
​
* 경제적 영향:
   - 일을 빨리 배우는 AI가 경제에 배포되면 매우 빠른 경제 성장 가능
   - 규제가 덜한 나라들의 경제 성장이 더 빠를 것
   - 광범위한 배포로 인한 지능 폭발 가능성
​
* 정렬(Alignment)의 미래
"지각 있는 생명체를 아끼는 AI":
Ilya의 핵심 제안은 인간만이 아닌 모든 지각 있는 생명체를 아끼도록 정렬된 AI입니다. 이것이 인간만 아끼는 것보다 더 쉬울 수 있는 이유는 AI 자체가 지각이 있을 것이기 때문입니다(거울 뉴런 효과).
​
* 정렬의 어려움:
   - 인간 가치를 배우는 능력과 최적화하는 능력 모두 취약
   - 이 모든 것이 신뢰할 수 없는 일반화의 사례
   - 일반화가 훨씬 더 좋다면 어떻게 될까?
​ 
* 장기 균형:
   - 모든 사람이 자신의 AI를 갖는 방법 - 하지만 사람은 더 이상 참여자가 아님
   - Neuralink++ 같은 것으로 "부분적 AI(part-AI)"가 되는 것 - Ilya가 선호하는 해결책

* 연구적 취향과 미적 감각
Ilya의 연구 성공 비결은 **"AI가 어떠해야 하는가에 대한 미적 감각"**입니다:
   - 사람들이 어떠한지 '올바르게' 생각하기
   - 뇌에서 영감을 받되 올바르게 받기 (뉴런의 중요성, 분산 표현, 경험 학습)
   - 아름다움과 단순함 찾기
   - "하향식 믿음" - 버그가 있어도 계속 밀고 나가게 해주는 확신
​

* 주요 포인트 정리
   - 패러다임 전환: 스케일링 시대 → 연구 시대로 전환. 단순 확장은 한계에 도달
   - 모델의 한계: 평가 점수와 실제 성능의 괴리는 과최적화와 일반화 부족 때문
   - 인간의 우월성: 인간은 적은 데이터로 더 깊고 신뢰성 있게 학습. "It" 팩터 존재
   - 가치 함수의 핵심: 감정은 진화가 부여한 가치 함수. 효율적 학습의 핵심이며, AI도 구현 가능
   - SSI의 비전: 모든 것을 아는 AI가 아닌 빠르게 배우는 AI. 지속적 학습과 배포를 통한 초지능 달성
   - 정렬 전략: 지각 있는 생명체를 아끼는 AI + 인간과 AI의 부분적 융합
   - 타임라인: 초지능 도달까지 5~20년
   - 연구 철학: 미적 감각, 뇌로부터의 올바른 영감, 하향식 믿음이 돌파구의 열쇠
   - 다양성 문제: 사전 학습 때문에 모델들이 비슷함. RL과 사후 학습에서 차별화 시작
   - 경쟁과 협력: AI가 강력해질수록 기업들의 안전에 대한 협력과 정부 개입 증가 예상
