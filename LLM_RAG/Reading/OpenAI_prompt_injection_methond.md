
* 원문링크 : https://openai.com/index/prompt-injections/

  - OpenAI가 AI 안전성 관련 중요한 보안 위협인 프롬프트 인젝션(prompt injection)에 대해 설명하고 방어법을 공개.
  - 프롬프트 인젝션은 제3자가 악의적 지시를 주입해 AI를 조작하는 공격 방식.
  - 오늘날 AI는 인터넷 등 다양한 출처의 정보를 활용하기 때문에 잘못된 정보 제공부터 은행 계좌 같은 민감 정보 유출까지 가능한 위험한 공격.
  - OpenAI는 이를 방어하기 위해 프롬프트 주입 패턴 학습, 자동화된 모니터링, 레드티밍(red-teaming), 접근 권한 설정 등의 기법을 적용하고 있다고 함. 
