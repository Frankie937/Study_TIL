(아직 정리는 안됨) 

------------- < 벨루가 RAG 시스템 - 20250428 > -------------

"embed-multilingual-v3.0"
"rerank-multilingual-v3.0"
delimiter delimiter delimiter delimiter delimiter
quotechar quotechar

loader = DataFrameLoader(df, page_content_column = "Name")
페이지 컨테츠로 갖고올 컬럼을 지정

```python 
docs = loader.load()

docs[0].page_content
docs[0].metadata
lazy_load() : generator 느낌
for row in loader.lazy_load():
print(row)
break
```

- Dense 검색
-> 의미적으로 비슷한 문장을 찾음
- Sparse 검색
-> 키워드 기반 검색
- Graph RAG
-> 정확한 관계 매칭 및 방향성 보장
-> Multi-hop 추론이 가능
예: 삼성전자가 출시한 제품의 출시 연도는 ?
-> (삼성전자) - [:출시] - (제품) - [:출시연도] > (2023)

문서형식이 워낙 가지각색이라...
시행착오도 굉장히 많고, 모든 케이스르 다룰 수는 없고
복잡해지면 유지보수도 힘들어지고

기준을 정하는 것도 굉장히 힘들어짐
graph를 학습시켜야 하는데
llm을 학습시켜서 노드로 관계를
문서마다 재편이 이루어져야 함

성능 개선 / 보편이 이루어져야 함

유저입장에서 어떤 문서를 올리더라도
최소한의 정확도가 보장되려면
청킹을 제대로 하고 리트리버에서 먼저 제대로된 정확도가 나와야
어떤 llm이 붙어도 어떤 문서가 붙어도 최소한의 정확도가 나올 것이라는 보장이 있을 수 있음

graph rag에서 관계형성이라는 게 굉장히 어려워서
기본적으로는 벡터서치로 하고

어려운 질문 - graph rag로 풀어보려고 하는 시도...

- Table Summary Indexing
테이블 기반 질문에 정밀하게 답할 수 있도록 미리 구조화, 요약, 스키마화

똑같은 llm을 쓰더라도 인신률을 높이는 방법도 있고
똑같은 vision을 쓴다고 해도 성능이 달라지기에

prompt 엔지니어링을 모든 고객에게 맞추기 어려움
b2b는 웬만하면 맞추더라도 b2c는 정말 어려움
비전을 쓰도록 유도한다고 하심
범용 prompt를 쓰면서 어려운 점들 ?
100번을 넘게 prompt를 고침

< 도입시 현실적인 문제와 해결방안 >

- 도메인이 정의되지 않은 문서의 그래프 구성 (Graph RAG)
리랭커를 못 쓰는 환경에서도 리랭킹을 쓸 수 있도록 고민
- 질문과 문서의 언어가 다를 경우 (다국어 대응)

쿼리변환
다른 언어보다 RAG 할 때, 한글 난이도가 4-5배는 높은 것 같음
비용문제도 큼
(graph rag는 시간도 많이 걸리고 비용이 많이 듦)

< Multi RAG 실행을 위한 langGraph 전략적 선택 >

- 랭그래프 핵식역할
흐름 설명 : 사용자질문 -> 분류 -> 분기 -> 응답선택
- (질문) 리랭커모델 어떤 거 사용하는 지?
-> 여러 개를 쓸 수 있게 되어 있는데
기본으로는 ,cohere/bge m3/도야지(?)
하나가 좋다고 말씀드리기는 어렵고
사실, 일반 텍스트같은 경우는 그렇게 리랭커로 차이는 없었음
리랭커의 역할 보다는 임베딩을 더 중점적으로 신경써서 정확도를 높이는 게 중요해보임
그게 더 효과가 좋을 것으로 예상

속도, 토큰핸들링
임베딩 > 청크사이즈
고유언어에 대한 성능

- 파인튜닝 방향을 도메인 지식에 맞추면 가치가 있다고 생각
그러나 임베딩을 도메인지식에 맞추는게 아니라 범용으로 한다면, 파인튜닝하는 것 맞지 않음 (성능 1-2프로 올린다고 해서 )

로컬모델의 한글성능 많이 조항지

로컬모델은 리소스를 다양하게 잘 쓸 수 있는 환경이긴 함
지금수준에서 llm을 탓할 수 없다
마지막 prompt 중요해짐

- *임베딩모델, 차원수 중요!!!!
청킹 쪽과 임베딩모델 쪽이 굉장히 중요한 영역으로 봄
리트리버에 더 많은 투자를 해야 한다.!

로컬모델의 prompt - 마지막 prompt에 변동폭이 큼 (프롬프트 엔지니어링에 더 민감함)
범용보델은 로컬모델보단 prompt에 있어서 변동폭이 크진 않음

현업이 굉장히 귀찮아 하는 것 - 문서파싱 쪽이다

qwen / mistral

매우유사한 메타데이터

오픈소스에 넘 기대하지 말자
pd

- 평가
- LAGASE
